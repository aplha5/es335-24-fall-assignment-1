{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5i7mOubBCo3"
   },
   "source": [
    "# Notebook to demonstrate Zero shot and Few shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "akrfOPGpI1gh",
    "outputId": "8ee40de3-daa7-4f95-b5f1-7441bfb1706e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API key is: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "\n",
    "# Specify the path to your .env file\n",
    "env_path = \"C:/Users/Tarun/Documents/apikey.env\"  # Replace with the actual path to your .env file\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Access the API key from the environment variable\n",
    "Groq_Token = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Check if the API key was set correctly\n",
    "if Groq_Token is None:\n",
    "    raise ValueError(\"The API key is not set. Please ensure that the .env file contains the correct API key.\")\n",
    "\n",
    "print(\"The API key is:\", Groq_Token)   #remove this\n",
    "\n",
    "# Groq API and Models\n",
    "groq_models = {\n",
    "    \"llama3-70b\": \"llama3-70b-8192\",\n",
    "    \"mixtral\": \"mixtral-8x7b-32768\",\n",
    "    \"gemma-7b\": \"gemma-7b-it\",\n",
    "    \"llama3.1-70b\": \"llama-3.1-70b-versatile\",\n",
    "    \"llama3-8b\": \"llama3-8b-8192\",\n",
    "    \"llama3.1-8b\": \"llama-3.1-8b-instant\",\n",
    "    \"gemma-9b\": \"gemma2-9b-it\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9gHQvZrBCpE"
   },
   "source": [
    "# Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KopzMNeMibXr",
    "outputId": "af52c9c7-adc1-414e-903b-cca4753e20ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After analyzing the provided featurized accelerometer data, I classify the activity performed as **Walking**.\n",
      "\n",
      "My reasoning is based on the following observations:\n",
      "\n",
      "1. **Magnitude of acceleration values**: The data shows a mix of moderate to high-magnitude acceleration values, which is consistent with the dynamic movements involved in walking.\n",
      "2. **Patterns of acceleration**: The data exhibits a repetitive pattern of acceleration and deceleration, which is typical of the gait cycle in walking. The alternating patterns of positive and negative values suggest the up-and-down and side-to-side movements of the legs and arms during walking.\n",
      "3. **Frequency content**: Although the frequency domain is not explicitly provided, the time-domain data suggests a frequency content that is consistent with the typical walking frequency range (around 1-2 Hz).\n",
      "4. **Lack of high-frequency noise**: The data does not show excessive high-frequency noise, which is often present in activities like running or jumping.\n",
      "\n",
      "While other activities, such as jogging or climbing stairs, could also exhibit similar patterns, the overall characteristics of the data suggest that walking is the most likely activity being performed.\n"
     ]
    }
   ],
   "source": [
    "# Featurized accelerometer data (this is the data you provided in the sentence)\n",
    "data = \"{2.8858451e-001 -2.0294171e-002 -1.3290514e-001 -9.9527860e-001 -9.8311061e-001 -9.1352645e-001 -9.9511208e-001 -9.8318457e-001 -9.2352702e-001 -9.3472378e-001 -5.6737807e-001 -7.4441253e-001  8.5294738e-001  6.8584458e-001  8.1426278e-001 -9.6552279e-001 -9.9994465e-001 -9.9986303e-001 -9.9461218e-001 -9.9423081e-001 -9.8761392e-001 -9.4321999e-001 -4.0774707e-001 -6.7933751e-001 -6.0212187e-001  9.2929351e-001 -8.5301114e-001  3.5990976e-001 -5.8526382e-002  2.5689154e-001 -2.2484763e-001  2.6410572e-001 -9.5245630e-002  2.7885143e-001 -4.6508457e-001  4.9193596e-001 -1.9088356e-001  3.7631389e-001  4.3512919e-001  6.6079033e-001  9.6339614e-001 -1.4083968e-001  1.1537494e-001 -9.8524969e-001 -9.8170843e-001 -8.7762497e-001 -9.8500137e-001 -9.8441622e-001 -8.9467735e-001  8.9205451e-001 -1.6126549e-001  1.2465977e-001  9.7743631e-001 -1.2321341e-001  5.6482734e-002 -3.7542596e-001  8.9946864e-001 -9.7090521e-001 -9.7551037e-001 -9.8432539e-001 -9.8884915e-001 -9.1774264e-001 -1.0000000e+000 -1.0000000e+000 }\"\n",
    "\n",
    "# System Prompts\n",
    "query = f\"\"\"\n",
    "* You are an activity classification model.\n",
    "* Your task is to analyze the given featurized accelerometer data and classify the activity performed.\n",
    "* Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Data: {data}\n",
    "\"\"\"\n",
    "\n",
    "# To use Groq LLMs \n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6DurgEIBCpI"
   },
   "source": [
    "# Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VQ5O3D2j6z9",
    "outputId": "36e02c91-3b2a-40e1-c86e-9b52e30066ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided featurized accelerometer data, I classify the activity as **laying**.\n",
      "\n",
      "My reasoning is as follows:\n",
      "\n",
      "* The data exhibits a relatively low magnitude of acceleration values, which is consistent with laying down.\n",
      "* The values are also relatively stable and consistent, indicating a lack of significant movement or activity.\n",
      "* The data does not show the characteristic patterns of walking, such as periodic peaks and valleys, which are typical of walking activities.\n",
      "* The data also does not exhibit the higher magnitude acceleration values that are typical of activities like walking upstairs or downstairs.\n",
      "\n",
      "Overall, the data suggests a relatively stationary and calm state, which is consistent with the activity of laying down.\n"
     ]
    }
   ],
   "source": [
    "# Example featurized accelerometer data and random activity labels\n",
    "examples = [\n",
    "    (\"9.9348603e-001 -9.9424782e-001 -9.9994898e-001 -9.9454718e-001 -6.1976763e-001  2.9284049e-001 -1.7688920e-001 -1.4577921e-001 -1.2407233e-001 -9.9478319e-001 -9.8298410e-001 -9.3926865e-001 -9.9542175e-001 -9.8313297e-001 -9.0616498e-001 -9.9688864e-001 -9.8451927e-001 -9.3208200e-001 -9.9375634e-001 -9.8316285e-001 -8.8505422e-001 -9.9396185e-001 -9.9344611e-001 -9.2342772e-001 -9.7473271e-001 -9.9996838e-001 -9.9968911e-001 -9.9489148e-001 -9.9592602e-001 -9.8970889e-001 -9.8799115e-001 -9.4635692e-001 -9.0474776e-001 -5.9130248e-001 -1.0000000e+000 -1.0000000e+000 -1.0000000e+000  2.5248290e-001  1.3183575e-001 -5.2050251e-002  1.4205056e-001 -1.5068250e-001 -2.2054694e-001 -5.5873853e-001  2.4676868e-001 -7.4155206e-003 -9.9996279e-001 -9.9998650e-001 -9.9997907e-001 -9.9996244e-001 -9.9993222e-001 -9.9972512e-001 -9.9967039e-001 -9.9998582e-001 -9.9996867e-001 -9.9997686e-001 -9.9986966e-001 -9.9977613e-001 -9.9997115e-001 -9.9991925e-001 -9.9965680e-001 -9.9986046e-001 -9.9986695e-001 -9.9986301e-001\", \"walking\"),\n",
    "    (\"2.8858451e-001 -2.0294171e-002 -1.3290514e-001 -9.9527860e-001 -9.8311061e-001 -9.1352645e-001 -9.9511208e-001 -9.8318457e-001 -9.2352702e-001 -9.3472378e-001 -5.6737807e-001 -7.4441253e-001  8.5294738e-001  6.8584458e-001  8.1426278e-001 -9.6552279e-001 -9.9994465e-001 -9.9986303e-001 -9.9461218e-001 -9.9423081e-001 -9.8761392e-001 -9.4321999e-001 -4.0774707e-001 -6.7933751e-001 -6.0212187e-001  9.2929351e-001 -8.5301114e-001  3.5990976e-001 -5.8526382e-002  2.5689154e-001 -2.2484763e-001  2.6410572e-001 -9.5245630e-002  2.7885143e-001 -4.6508457e-001  4.9193596e-001 -1.9088356e-001  3.7631389e-001  4.3512919e-001  6.6079033e-001  9.6339614e-001 -1.4083968e-001  1.1537494e-001 -9.8524969e-001 -9.8170843e-001 -8.7762497e-001 -9.8500137e-001 -9.8441622e-001 -8.9467735e-001  8.9205451e-001 -1.6126549e-001  1.2465977e-001  9.7743631e-001 -1.2321341e-001  5.6482734e-002 -3.7542596e-001  8.9946864e-001 -9.7090521e-001 -9.7551037e-001 -9.8432539e-001 -9.8884915e-001 -9.1774264e-001 -1.0000000e+000 -1.0000000e+000\", \"laying\"),\n",
    "    (\"1.1000000e+000 -3.8700000e-002 -2.8400000e-001 -8.4700000e-001 -9.9400000e-001 -9.6900000e-001 -9.7500000e-001 -9.8200000e-001 -9.5400000e-001 -9.7200000e-001 -9.5800000e-001 -8.8200000e-001 -9.7100000e-001 -9.8100000e-001 -8.8500000e-001 -9.6500000e-001 -9.9000000e-001 -9.8100000e-001 -9.7100000e-001 -9.7600000e-001 -9.8500000e-001 -9.8700000e-001 -9.5000000e-001 -9.3400000e-001 -9.6100000e-001 -9.8500000e-001 -9.6700000e-001 -9.8000000e-001 -9.8700000e-001 -9.7800000e-001 -9.9300000e-001 -9.7400000e-001 -9.7600000e-001 -9.9800000e-001 -1.0000000e+000 -1.0000000e+000 -1.0000000e+000\", \"sitting\"),\n",
    "    (\"9.8400000e-001 -9.9500000e-001 -9.7800000e-001 -9.8900000e-001 -8.7600000e-001  9.2600000e-001 -1.7600000e-001 -1.2300000e-001 -1.5100000e-001 -9.9600000e-001 -9.8300000e-001 -9.4300000e-001 -9.8100000e-001 -9.8300000e-001 -9.0600000e-001 -9.7600000e-001 -9.8400000e-001 -9.3200000e-001 -9.9700000e-001 -9.8200000e-001 -8.7800000e-001 -9.9400000e-001 -9.9300000e-001 -9.2500000e-001 -9.7400000e-001 -9.6900000e-001 -9.8900000e-001 -9.9400000e-001 -9.9600000e-001 -9.8900000e-001 -9.7900000e-001 -9.4600000e-001 -9.0600000e-001 -5.9200000e-001 -1.0000000e+000 -1.0000000e+000 -1.0000000e+000\", \"standing\"),\n",
    "    (\"2.6100000e-001 -9.9500000e-002 -9.8900000e-001 -9.8900000e-001 -9.9400000e-001 -9.4300000e-001 -9.7800000e-001 -9.8700000e-001 -9.9700000e-001 -9.8200000e-001 -8.7800000e-001 -9.8500000e-001 -9.8700000e-001 -9.8500000e-001 -9.9400000e-001 -9.9400000e-001 -9.8800000e-001 -9.4200000e-001 -9.9700000e-001 -9.8700000e-001 -8.8700000e-001 -9.9300000e-001 -9.8700000e-001 -9.8600000e-001 -9.8700000e-001 -9.7600000e-001 -9.8300000e-001 -9.8100000e-001 -9.8700000e-001 -9.8200000e-001 -8.7800000e-001 -9.8500000e-001 -9.9300000e-001 -9.6700000e-001 -9.8500000e-001 -9.7800000e-001 -9.8700000e-001 -9.8700000e-001 -9.9900000e-001 -1.0000000e+000 -1.0000000e+000 -1.0000000e+000\", \"walking_upstairs\"),\n",
    "    (\"1.0000000e+000 -9.6100000e-001 -9.9200000e-001 -9.9000000e-001 -9.8700000e-001 -9.7500000e-001 -9.8200000e-001 -9.8500000e-001 -9.8700000e-001 -9.8300000e-001 -9.8500000e-001 -9.8700000e-001 -9.8700000e-001 -9.8600000e-001 -9.8700000e-001 -9.9600000e-001 -9.8900000e-001 -9.8700000e-001 -9.9700000e-001 -9.8700000e-001 -9.7800000e-001 -9.8300000e-001 -9.8500000e-001 -9.8600000e-001 -9.8700000e-001 -9.8200000e-001 -9.8700000e-001 -9.8700000e-001 -9.9500000e-001 -9.9700000e-001 -9.8700000e-001 -9.8700000e-001 -9.8700000e-001 -9.9500000e-001 -9.8700000e-001 -9.9000000e-001 -9.9200000e-001 -9.8300000e-001 -9.9900000e-001 -9.8700000e-001 -9.8700000e-001 -9.8700000e-001\", \"walking_downstairs\")\n",
    "]\n",
    "\n",
    "# System Prompts\n",
    "examples_text = \"\\n\".join([f\"Data: '{data}'\\nActivity: {label}\\n\" for data, label in examples])\n",
    "\n",
    "query = f\"\"\"\n",
    "* You are an activity recognition model.\n",
    "* Your task is to analyze the provided featurized accelerometer data and classify the activity as 'walking', 'laying', 'sitting', 'standing', 'walking_upstairs', or 'walking_downstairs'.\n",
    "* Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Here are a few examples:\n",
    "{examples_text}\n",
    "\n",
    "Data: {examples[1][0]}\n",
    "\"\"\"\n",
    "\n",
    "# To use Groq LLMs\n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API key is: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "\n",
    "# Specify the path to your .env file\n",
    "env_path = \"C:/Users/Tarun/Documents/apikey.env\"  # Replace with the actual path to your .env file\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Access the API key from the environment variable\n",
    "Groq_Token = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Check if the API key was set correctly\n",
    "if Groq_Token is None:\n",
    "    raise ValueError(\"The API key is not set. Please ensure that the .env file contains the correct API key.\")\n",
    "\n",
    "print(\"The API key is:\", Groq_Token)   #remove this\n",
    "\n",
    "# Groq API and Models\n",
    "groq_models = {\n",
    "    \"llama3-70b\": \"llama3-70b-8192\",\n",
    "    \"mixtral\": \"mixtral-8x7b-32768\",\n",
    "    \"gemma-7b\": \"gemma-7b-it\",\n",
    "    \"llama3.1-70b\": \"llama-3.1-70b-versatile\",\n",
    "    \"llama3-8b\": \"llama3-8b-8192\",\n",
    "    \"llama3.1-8b\": \"llama-3.1-8b-instant\",\n",
    "    \"gemma-9b\": \"gemma2-9b-it\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_activity = {\n",
    "    \"WALKING\": 1,\n",
    "    \"WALKING_UPSTAIRS\": 2,\n",
    "    \"WALKING_DOWNSTAIRS\": 3,\n",
    "    \"SITTING\": 4,\n",
    "    \"STANDING\": 5,\n",
    "    \"LAYING\": 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"WALKING\", \"WALKING_UPSTAIRS\", \"WALKING_DOWNSTAIRS\", \"SITTING\", \"STANDING\", \"LAYING\"]\n",
    "\n",
    "#Features \n",
    "features_dataset = pd.read_csv(\"C:/Users/Tarun/Downloads/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/features.txt\", sep = \" \", header = None)\n",
    "Feature_names = features_dataset[1].tolist()\n",
    "\n",
    "# Sample IMU data (replace these with actual values)\n",
    "Test_Data = pd.read_csv(\"C:/Users/Tarun/Downloads/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/test/X_test.txt\", header = None,sep= r'\\s+')\n",
    "Test_labels = pd.read_csv(\"C:/Users/Tarun/Downloads/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/test/y_test.txt\", header = None,sep= r'\\s+')\n",
    "Test_labels_data = Test_labels[0].tolist()\n",
    "\n",
    "# Example Data\n",
    "Example_Data = pd.read_csv(\"C:/Users/Tarun/Downloads/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/train/X_train.txt\", header=None, sep=r'\\s+')\n",
    "Example_Data_labels = pd.read_csv(\"C:/Users/Tarun/Downloads/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/train/y_train.txt\", header=None, sep=r'\\s+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Acceleration Data: [0.28858451, -0.020294171, -0.13290514, -0.9952786, -0.98311061, -0.91352645, -0.99511208, -0.98318457, -0.92352702, -0.93472378, -0.56737807, -0.74441253, 0.85294738, 0.68584458, 0.81426278]\n",
      "Label: STANDING\n",
      "\n",
      "Example 2:\n",
      "Acceleration Data: [0.27841883, -0.016410568, -0.12352019, -0.99824528, -0.97530022, -0.96032199, -0.99880719, -0.97491437, -0.95768622, -0.94306751, -0.55785126, -0.81840869, 0.84930787, 0.68584458, 0.82263681]\n",
      "Label: STANDING\n",
      "\n",
      "Example 3:\n",
      "Acceleration Data: [0.27965306, -0.019467156, -0.11346169, -0.99537956, -0.96718701, -0.97894396, -0.99651994, -0.96366837, -0.97746859, -0.93869155, -0.55785126, -0.81840869, 0.84360895, 0.68240094, 0.83934417]\n",
      "Label: STANDING\n",
      "\n",
      "Example 4:\n",
      "Acceleration Data: [0.27917394, -0.026200646, -0.12328257, -0.99609149, -0.9834027, -0.9906751, -0.99709947, -0.98274984, -0.9893025, -0.93869155, -0.57615889, -0.82971145, 0.84360895, 0.68240094, 0.83786929]\n",
      "Label: STANDING\n",
      "\n",
      "Example 5:\n",
      "Acceleration Data: [0.27662877, -0.016569655, -0.11536185, -0.99813862, -0.98081727, -0.99048163, -0.99832113, -0.97967187, -0.99044113, -0.94246912, -0.56917385, -0.82470529, 0.84909512, 0.68324978, 0.83786929]\n",
      "Label: STANDING\n",
      "\n",
      "True label: 5\n",
      "Response for iteration 1: WALKING\n",
      "True label: 5\n",
      "Response for iteration 2: WALKING\n",
      "True label: 5\n",
      "Response for iteration 3: WALKING\n",
      "True label: 5\n",
      "Response for iteration 4: WALKING\n",
      "True label: 5\n",
      "Response for iteration 5: WALKING\n",
      "True label: 5\n",
      "Response for iteration 6: WALKING\n",
      "True label: 5\n",
      "Response for iteration 7: WALKING\n",
      "True label: 5\n",
      "Response for iteration 8: WALKING\n",
      "True label: 5\n",
      "Response for iteration 9: WALKING\n",
      "True label: 5\n",
      "Response for iteration 10: WALKING\n",
      "True label: 5\n",
      "Response for iteration 11: WALKING\n",
      "True label: 5\n",
      "Response for iteration 12: WALKING\n",
      "True label: 5\n",
      "Response for iteration 13: WALKING\n",
      "True label: 5\n",
      "Response for iteration 14: WALKING\n",
      "True label: 5\n",
      "Response for iteration 15: WALKING\n",
      "True label: 5\n",
      "Response for iteration 16: WALKING\n",
      "True label: 5\n",
      "Response for iteration 17: WALKING\n",
      "True label: 5\n",
      "Response for iteration 18: WALKING\n",
      "True label: 5\n",
      "Response for iteration 19: WALKING\n",
      "True label: 5\n",
      "Response for iteration 20: WALKING\n",
      "Final Predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "few shot accuracy\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Storing and formatting Examples\n",
    "formatted_examples = []\n",
    "for n in range(0, 5):\n",
    "    # Get accelerometer data for the current example and its corresponding label\n",
    "    Acc_Data = Example_Data.iloc[n].tolist()\n",
    "    label = categories[Example_Data_labels.iloc[n, 0] - 1]\n",
    "    # Format the accelerometer data and label into a string\n",
    "    formatted_example = f\"Example {n+1}:\\n\" \\\n",
    "                        f\"Acceleration Data: {Acc_Data[:15]}\\n\" \\\n",
    "                        f\"Label: {label}\\n\"\n",
    "    formatted_examples.append(formatted_example)\n",
    "\n",
    "examples_string = \"\\n\".join(formatted_examples)\n",
    "\n",
    "print(examples_string)\n",
    "    \n",
    "#for getting accuracy we will predicte data on some number of points and then calculate accuracy\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "\n",
    "for n in range(20):\n",
    "    Acc_Data = Test_Data.iloc[n].tolist()\n",
    "    Acc_Data = Acc_Data[:15]\n",
    "    # print(Test_labels_data)\n",
    "    true_labels.append(Test_labels_data[n])\n",
    "    print(f\"True label: {true_labels[-1]}\")\n",
    "\n",
    "    # System Prompt\n",
    "    query = f\"\"\"\n",
    "    * You are an activity classification model.\n",
    "    * Your task is to analyze the given featurized accelerometer data and classify the activity performed.\n",
    "    * Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "    * The data is {Acc_Data}\n",
    "    * The person’s action belongs to one of the following categories: {', '.join(categories)}.\n",
    "    Give Activty response in one word : \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Sending the request and getting the response\n",
    "    model_name = \"llama3-70b\"\n",
    "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "    answer = llm.invoke(query)\n",
    "    \n",
    "    # Append the response and print progress\n",
    "    predictions.append(mapping_activity[answer.content.strip()])\n",
    "    print(f\"Response for iteration {n+1}: {answer.content.strip()}\")\n",
    "\n",
    "print(\"Final Predictions:\", predictions)\n",
    "print(\"few shot accuracy\")\n",
    "print(accuracy_score(true_labels, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(max_depth=25)\n",
    "\n",
    "# Fit the model\n",
    "dt_model.fit(Example_Data, Example_Data_labels)\n",
    "\n",
    "# Predict the labels on the test set\n",
    "dt_predictions = dt_model.predict(Test_Data)\n",
    "dt_predictions = pd.Series(dt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.8551068883610451\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy for both models\n",
    "dt_accuracy = accuracy_score(Test_labels, dt_predictions)\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero-Shot Learning (ZSL) Limitations:\n",
    "#### Dependence on Semantic Descriptions:\n",
    "\n",
    "ZSL relies on accurate semantic descriptions or attributes that link known classes to unknown classes. In human activity classification, defining these attributes meaningfully is challenging because physical activities may not have clear, distinctive features that can be generalized.\n",
    "#### Generalization to Unseen Activities:\n",
    "\n",
    "ZSL assumes that the unseen classes (new activities) can be described or inferred based on the relationships with seen classes. However, human activities can vary widely, making it difficult to model unseen activities based solely on known ones. For example, subtle variations in movement might not be captured adequately by the features used in ZSL.\n",
    "#### Bias Towards Seen Classes:\n",
    "\n",
    "ZSL models often exhibit a bias towards predicting seen classes over unseen ones, especially when the unseen activities are significantly different from those in the training set. This bias can lead to poor performance in classifying new human activities.\n",
    "#### Feature Similarity and Ambiguity:\n",
    "\n",
    "Featurized accelerometer data from different activities might be similar, leading to ambiguity. For instance, walking and jogging might have overlapping features, making it difficult for a ZSL model to distinguish between them without prior examples.\n",
    "#### Scalability Issues:\n",
    "\n",
    "As the number of unseen classes increases, the complexity of accurately describing and linking them to seen classes grows, which can reduce the effectiveness of ZSL models in human activity classification.\n",
    "## Few-Shot Learning (FSL) Limitations:\n",
    "#### Data Scarcity and Representation:\n",
    "\n",
    "FSL requires a small number of examples to generalize to new classes. However, in the context of human activity classification, the few available examples might not capture the full variability of the activity, leading to poor generalization.\n",
    "#### Overfitting on Limited Data:\n",
    "\n",
    "With very few examples, FSL models are prone to overfitting, where they learn noise or specific characteristics of the limited training data rather than general patterns that apply to the broader class of activities.\n",
    "#### Difficulty in Feature Extraction:\n",
    "\n",
    "Extracting robust and discriminative features from accelerometer data with limited examples is challenging. FSL models might struggle to learn meaningful representations of activities, especially when the activities are complex or involve subtle differences.\n",
    "##### Class Imbalance:\n",
    "\n",
    "If there is an imbalance in the number of examples per class (even in the few-shot setting), the model might perform well on classes with more examples while underperforming on others, leading to skewed classification results.\n",
    "Transfer Learning Limitations:\n",
    "\n",
    "FSL often relies on transfer learning from a related domain or task. However, the transferability of features or knowledge might be limited when the source and target activities are too different, reducing the effectiveness of the approach.\n",
    "Sensitivity to Noise:\n",
    "\n",
    "Few-shot models are particularly sensitive to noise in the training data. If the limited examples are noisy or contain errors, the model’s performance can degrade significantly, making it less reliable for real-world human activity classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Activity Data: 1.2000000e+000 -3.8700000e-001 2.8400000e-001 7.4700000e-001 5.9400000e-001 1.6900000e-001 2.7500000e-001 3.8200000e-001 4.5400000e-001 5.7200000e-001 6.5800000e-001 7.8200000e-001 8.7100000e-001 9.8100000e-001 6.8500000e-001 7.6500000e-001 8.9000000e-001 9.8100000e-001 1.0710000e+000 1.1760000e+000 1.2850000e+000 1.3870000e+000 1.5000000e+000 1.6340000e+000 1.7610000e+000 1.8850000e+000 1.9670000e+000 1.9880000e+000 2.0870000e+000 2.1780000e+000 2.1930000e+000 2.3060000e+000 2.4120000e+000 2.4980000e+000 2.6000000e+000 2.7140000e+000 2.8310000e+000 2.9510000e+000 3.1000000e+000 3.2870000e+000 3.4120000e+000 3.5980000e+000 3.7200000e+000 3.8500000e+000 3.9700000e+000 4.1000000e+000 4.2200000e+000 4.3400000e+000 4.4500000e+000 4.5600000e+000 4.6700000e+000 4.7700000e+000 4.8900000e+000 5.0000000e+000 5.1200000e+000 5.2200000e+000 5.3400000e+000 5.4500000e+000\n",
      "Model's Classification: Based on the provided featurized accelerometer data, I classify the activity as **walking**.\n",
      "\n",
      "My reasoning is as follows:\n",
      "\n",
      "* The data shows a mix of high and low values, indicating a dynamic movement pattern.\n",
      "* The presence of both positive and negative values suggests that the movement is not purely linear, but rather involves some degree of oscillation or rotation.\n",
      "* The overall magnitude of the values is relatively high, indicating a more energetic movement.\n",
      "* The pattern of the data does not resemble the characteristic patterns of laying, sitting, or standing, which tend to have more stable and consistent values.\n",
      "* The data is more similar to the patterns seen in walking, walking_upstairs, and walking_downstairs, but the magnitude and oscillation patterns are more consistent with walking.\n",
      "\n",
      "Please note that this classification is based on the provided data and may not be 100% accurate. Additional data or context may be necessary to confirm the classification.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create new activity data\n",
    "# This is a fictional dataset representing the new activity \"jumping\"\n",
    "new_activity_data = \"1.2000000e+000 -3.8700000e-001 2.8400000e-001 7.4700000e-001 5.9400000e-001 1.6900000e-001 2.7500000e-001 3.8200000e-001 4.5400000e-001 5.7200000e-001 6.5800000e-001 7.8200000e-001 8.7100000e-001 9.8100000e-001 6.8500000e-001 7.6500000e-001 8.9000000e-001 9.8100000e-001 1.0710000e+000 1.1760000e+000 1.2850000e+000 1.3870000e+000 1.5000000e+000 1.6340000e+000 1.7610000e+000 1.8850000e+000 1.9670000e+000 1.9880000e+000 2.0870000e+000 2.1780000e+000 2.1930000e+000 2.3060000e+000 2.4120000e+000 2.4980000e+000 2.6000000e+000 2.7140000e+000 2.8310000e+000 2.9510000e+000 3.1000000e+000 3.2870000e+000 3.4120000e+000 3.5980000e+000 3.7200000e+000 3.8500000e+000 3.9700000e+000 4.1000000e+000 4.2200000e+000 4.3400000e+000 4.4500000e+000 4.5600000e+000 4.6700000e+000 4.7700000e+000 4.8900000e+000 5.0000000e+000 5.1200000e+000 5.2200000e+000 5.3400000e+000 5.4500000e+000\"\n",
    "\n",
    "# Step 2: Construct the query with new activity data\n",
    "query_with_new_activity = f\"\"\"\n",
    "* You are an activity recognition model.\n",
    "* Your task is to analyze the provided featurized accelerometer data and classify the activity as 'walking', 'laying', 'sitting', 'standing', 'walking_upstairs', or 'walking_downstairs'.\n",
    "* Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Here are a few examples:\n",
    "{examples_text}\n",
    "\n",
    "Data: {new_activity_data}\n",
    "\"\"\"\n",
    "\n",
    "# Step 3: Invoke the model and analyze the output\n",
    "answer_with_new_activity = llm.invoke(query_with_new_activity)\n",
    "\n",
    "# Print the model's classification and reasoning\n",
    "print(\"New Activity Data:\", new_activity_data)\n",
    "print(\"Model's Classification:\", answer_with_new_activity.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Activity Data (Low Values): 0.005 0.003 0.007 0.009 0.004 0.006 0.008 0.002 0.003 0.004 0.005 0.007 0.003 0.006 0.009 0.004 0.002 0.008 0.005 0.007 0.006 0.003 0.002 0.004 0.005 0.007 0.008 0.002 0.006 0.003 0.004 0.005 0.009 0.007 0.006 0.003 0.008 0.005 0.002 0.004 0.006 0.007 0.003 0.008 0.002 0.009 0.005 0.004 0.006 0.007 0.003 0.008 0.004 0.005 0.007 0.003 0.006 0.002\n",
      "Model's Classification: Based on the provided featurized accelerometer data, I classify the activity as **walking**.\n",
      "\n",
      "My reasoning is as follows:\n",
      "\n",
      "* The data exhibits a mix of small and moderate amplitude values, indicating a dynamic activity with some level of movement.\n",
      "* The values are not extremely high or low, which suggests that the activity is not too intense or too static.\n",
      "* The pattern of the data appears to be somewhat periodic, with a repeating sequence of values, which is consistent with the rhythmic motion of walking.\n",
      "* The overall range of values is relatively narrow, which is also consistent with walking, as it tends to involve more controlled and deliberate movements compared to other activities like running or jumping.\n",
      "\n",
      "While the data is not an exact match to the example walking data provided, the characteristics mentioned above lead me to conclude that the activity is likely walking.\n"
     ]
    }
   ],
   "source": [
    "# New activity data with low values (representing a low-intensity activity like \"crawling\")\n",
    "new_activity_data_low_values = \"0.005 0.003 0.007 0.009 0.004 0.006 0.008 0.002 0.003 0.004 0.005 0.007 0.003 0.006 0.009 0.004 0.002 0.008 0.005 0.007 0.006 0.003 0.002 0.004 0.005 0.007 0.008 0.002 0.006 0.003 0.004 0.005 0.009 0.007 0.006 0.003 0.008 0.005 0.002 0.004 0.006 0.007 0.003 0.008 0.002 0.009 0.005 0.004 0.006 0.007 0.003 0.008 0.004 0.005 0.007 0.003 0.006 0.002\"\n",
    "\n",
    "# Step 2: Construct the query with the new low-value activity data\n",
    "query_with_new_activity_low_values = f\"\"\"\n",
    "* You are an activity recognition model.\n",
    "* Your task is to analyze the provided featurized accelerometer data and classify the activity as 'walking', 'laying', 'sitting', 'standing', 'walking_upstairs', or 'walking_downstairs'.\n",
    "* Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Here are a few examples:\n",
    "{examples_text}\n",
    "\n",
    "Data: {new_activity_data_low_values}\n",
    "\"\"\"\n",
    "\n",
    "# Step 3: Invoke the model and analyze the output\n",
    "answer_with_new_activity_low_values = llm.invoke(query_with_new_activity_low_values)\n",
    "\n",
    "# Print the model's classification and reasoning\n",
    "print(\"New Activity Data (Low Values):\", new_activity_data_low_values)\n",
    "print(\"Model's Classification:\", answer_with_new_activity_low_values.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Activity Data (Mid Values): 20.5 30.3 40.001 55.2 70.6 25.7 35.9 45.8 60.3 22.1 33.7 48.4 72.6 29.8 50.1 65.9 23.4 39.5 54.2 78.3 27.6 46.7 63.2 21.8 36.3 49.9 67.4 28.2 41.6 53.1 74.5 26.8 48.7 60.4 80.1 24.9 38.2 55.6 69.3 31.7 43.8 57.4 77.2 30.6 52.9 61.2 85.5 22.5 44.1 58.3 74.8 29.1 47.2 64.5 81.9 26.4 40.5 59.8\n",
      "Model's Classification: Based on the provided featurized accelerometer data, I classify the activity as **walking**.\n",
      "\n",
      "My reasoning is as follows:\n",
      "\n",
      "* The data shows a mix of high and low values, indicating a dynamic movement pattern.\n",
      "* The values are not consistently high or low, which suggests that the movement is not static (e.g., laying or sitting).\n",
      "* The range of values is relatively large, which is consistent with the dynamic movement patterns observed during walking.\n",
      "* The data does not exhibit a clear periodic pattern, which is consistent with walking, as it can involve varying stride lengths and speeds.\n",
      "\n",
      "While the data does not perfectly match the walking example provided, the overall pattern and range of values suggest that the activity is likely walking.\n"
     ]
    }
   ],
   "source": [
    "# New activity data with values between 20 and 100 (representing a different kind of movement)\n",
    "new_activity_data_mid_values = \"20.5 30.3 40.001 55.2 70.6 25.7 35.9 45.8 60.3 22.1 33.7 48.4 72.6 29.8 50.1 65.9 23.4 39.5 54.2 78.3 27.6 46.7 63.2 21.8 36.3 49.9 67.4 28.2 41.6 53.1 74.5 26.8 48.7 60.4 80.1 24.9 38.2 55.6 69.3 31.7 43.8 57.4 77.2 30.6 52.9 61.2 85.5 22.5 44.1 58.3 74.8 29.1 47.2 64.5 81.9 26.4 40.5 59.8\"\n",
    "\n",
    "# Step 2: Construct the query with the new mid-value activity data\n",
    "query_with_new_activity_mid_values = f\"\"\"\n",
    "* You are an activity recognition model.\n",
    "* Your task is to analyze the provided featurized accelerometer data and classify the activity as 'walking', 'laying', 'sitting', 'standing', 'walking_upstairs', or 'walking_downstairs'.\n",
    "* Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Here are a few examples:\n",
    "{examples_text}\n",
    "\n",
    "Data: {new_activity_data_mid_values}\n",
    "\"\"\"\n",
    "\n",
    "# Step 3: Invoke the model and analyze the output\n",
    "answer_with_new_activity_mid_values = llm.invoke(query_with_new_activity_mid_values)\n",
    "\n",
    "# Print the model's classification and reasoning\n",
    "print(\"New Activity Data (Mid Values):\", new_activity_data_mid_values)\n",
    "print(\"Model's Classification:\", answer_with_new_activity_mid_values.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Activity Data (Mid Values): -20,-30,-40,-50,-60,-55,-75,-85,-90,-80,-100\n",
      "Model's Classification: Based on the provided featurized accelerometer data, I classify the activity as 'sitting'.\n",
      "\n",
      "My reasoning is as follows:\n",
      "\n",
      "* The data values are relatively small, indicating a low level of acceleration, which is consistent with sitting.\n",
      "* The values are also relatively stable, with no sudden changes or spikes, which suggests a stationary activity like sitting.\n",
      "* The range of values is also relatively narrow, which further supports the classification of sitting.\n",
      "\n",
      "Note that this is a simple classification based on the provided data, and more complex models or additional features may be needed to achieve higher accuracy.\n"
     ]
    }
   ],
   "source": [
    "# New activity data with values between 20 and 100 (representing a different kind of movement)\n",
    "new_activity_data_mid_values = \"-20,-30,-40,-50,-60,-55,-75,-85,-90,-80,-100\"\n",
    "\n",
    "# Step 2: Construct the query with the new mid-value activity data\n",
    "query_with_new_activity_mid_values = f\"\"\"\n",
    "* You are an activity recognition model.\n",
    "* Your task is to analyze the provided featurized accelerometer data and classify the activity as 'walking', 'laying', 'sitting', 'standing', 'walking_upstairs', or 'walking_downstairs'.\n",
    "* Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Here are a few examples:\n",
    "{examples_text}\n",
    "\n",
    "Data: {new_activity_data_mid_values}\n",
    "\"\"\"\n",
    "\n",
    "# Step 3: Invoke the model and analyze the output\n",
    "answer_with_new_activity_mid_values = llm.invoke(query_with_new_activity_mid_values)\n",
    "\n",
    "# Print the model's classification and reasoning\n",
    "print(\"New Activity Data (Mid Values):\", new_activity_data_mid_values)\n",
    "print(\"Model's Classification:\", answer_with_new_activity_mid_values.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Data: -8.1661498e-01 5.8978419e-01 -8.1934745e-01 -1.1230131e-01 7.9835922e-01 -8.2582382e-01 -7.3646524e-01 -2.0178176e-02 -2.7598979e-01 6.8232519e-01 -8.3778609e-01 -2.6903943e-02 2.5317565e-01 -3.8253690e-01 -8.5472078e-01 -3.3251763e-01 -6.8110754e-01 7.7051584e-01 4.1092368e-01 4.5790177e-01 9.2785239e-01 -2.7608404e-01 -9.4875751e-02 -9.7906945e-01 -3.1885324e-01 4.5527049e-03 1.9790732e-01 4.4537895e-01 -5.1042254e-01 -1.4307892e-01 3.7182939e-01 6.4876138e-01 -2.3875583e-01 -5.0715471e-01 1.7688760e-01 4.6456620e-01 -4.3557785e-02 -9.7556402e-01 6.0198468e-01 5.1404278e-01 -1.2889669e-01 -2.8068651e-01 -5.0785241e-01 -5.6356428e-01 -9.4313140e-01 -3.1636644e-01 8.8257361e-01 2.0456821e-01 2.6981084e-01 -2.6750392e-01 5.0885170e-01 5.6561270e-01 7.1913770e-01 -4.7596060e-01 -2.5182860e-01 1.4238865e-01 -8.3642003e-01 -1.7843159e-01 -6.6343232e-02 -9.2793784e-01\n",
      "Model's Response: Based on the provided featurized accelerometer data, I classify the activity as **walking**.\n",
      "\n",
      "My reasoning is based on the following features:\n",
      "\n",
      "* The data exhibits a mix of high and low values, indicating a dynamic movement pattern, which is consistent with walking.\n",
      "* The presence of both positive and negative values suggests a oscillating motion, which is typical of walking.\n",
      "* The amplitude of the values is relatively high, indicating a more energetic movement, which is also consistent with walking.\n",
      "\n",
      "While the data shares some similarities with other activities, such as walking upstairs or downstairs, the overall pattern and amplitude of the values suggest that walking is the most likely activity.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Generate random data\n",
    "# Assuming the original data has 60 dimensions with values roughly in the range [-1.0, 1.0]\n",
    "random_data = \" \".join([f\"{np.random.uniform(-1.0, 1.0):.7e}\" for _ in range(60)])\n",
    "\n",
    "# Step 2: Create a query with random data\n",
    "query_with_random_data = f\"\"\"\n",
    "* You are an activity recognition model.\n",
    "* Your task is to analyze the provided featurized accelerometer data and classify the activity as 'walking', 'laying', 'sitting', 'standing', 'walking_upstairs', or 'walking_downstairs'.\n",
    "* Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Here are a few examples:\n",
    "{examples_text}\n",
    "\n",
    "Data: {random_data}\n",
    "\"\"\"\n",
    "\n",
    "# Step 3: Invoke the model and report the results\n",
    "answer_with_random_data = llm.invoke(query_with_random_data)\n",
    "\n",
    "# Print the model's classification and reasoning\n",
    "print(\"Random Data:\", random_data)\n",
    "print(\"Model's Response:\", answer_with_random_data.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
